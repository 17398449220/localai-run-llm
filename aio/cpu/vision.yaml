backend: llama-cpp
context_size: 4096
f16: true
mmap: true
name: gpt-4-vision-preview

roles:
  user: "USER:"
  assistant: "ASSISTANT:"
  system: "SYSTEM:"

mmproj: bakllava.gguf
parameters:
  model: bakllava.gguf

template:
  chat: |
    A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.
    {{.Input}}
    ASSISTANT:

usage: |
    curl http://localhost:8080/v1/chat/completions -H "Content-Type: application/json" -d '{
        "model": "gpt-4-vision-preview",
        "messages": [{"role": "user", "content": [{"type":"text", "text": "What is in the image?"}, {"type": "image_url", "image_url": {"url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg" }}], "temperature": 0.9}]}'

# https://hf-mirror.com/mys/ggml_bakllava-1/tree/main
# 选择不同裁剪尺寸的：
download_files:
- filename: bakllava.gguf
  sha256: "5be58c339d8762e72d482a3e071a58d2df07df4a7aaabf8869415ae2b0f088d6"
  uri: https://hf-mirror.com/mys/ggml_bakllava-1/resolve/main/ggml-model-q4_k.gguf
# - filename: bakllava-mmproj.gguf
#   uri: https://hf-mirror.com/mys/ggml_bakllava-1/resolve/main/mmproj-model-f16.gguf